{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Stack Overflow Scraping\n"
      ],
      "metadata": {
        "id": "2dxDoLB3hqw3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNLy5ESafbT1",
        "outputId": "d34fdcad-a250-4785-f65d-5fe192400512"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.11.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.11.17)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n"
          ]
        }
      ],
      "source": [
        "pip install requests beautifulsoup4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import re\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "89xJIltRl7td",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9a0220d-3a82-473e-da1a-07bdbb371228"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Web Scraping Function Documentation\n",
        "\n",
        "## Overview\n",
        "This function is designed to scrape posts from a specific section of the Stack Overflow website, particularly the Python-tagged questions. It uses Python with libraries such as `requests` and `BeautifulSoup` to extract information from web pages. The function allows for customizable scraping based on different filters, a set number of pages, and a minimum view count threshold.\n",
        "\n",
        "## Function Signature\n",
        "```python\n",
        "def scrape(base_url, filters, total_pages=3, min_view_count=100):\n",
        "```\n",
        "\n",
        "## Parameters\n",
        "- `base_url` (str): The base URL of the section to scrape. For example, 'https://stackoverflow.com/questions/tagged/python'.\n",
        "- `filters` (list): A list of filters to apply. Each filter represents a different sorting method, such as 'RecentActivity', 'MostVotes', or 'MostFrequent'.\n",
        "- `total_pages` (int): The total number of pages to scrape across all filters. Default is 3.\n",
        "- `min_view_count` (int): The minimum number of views a post must have to be included. Default is 100.\n",
        "\n",
        "## Functionality\n",
        "1. **Header Configuration**: Sets a user-agent for HTTP requests to mimic a web browser.\n",
        "2. **Filter Distribution Logic**: Calculates how many pages to scrape per filter based on the total number of pages and the number of filters.\n",
        "3. **Scraping Loop**:\n",
        "   - Iterates over each filter and its assigned number of pages.\n",
        "   - Constructs the URL for each page and sends a GET request.\n",
        "   - Uses a delay to avoid rate limiting or server overload.\n",
        "   - Parses the HTML response using BeautifulSoup.\n",
        "4. **Post Data Extraction**:\n",
        "   - Extracts title, upvotes, answer count, view count, and the post's content.\n",
        "   - Converts view counts from strings to integers, handling 'k' (thousand) and 'm' (million) suffixes.\n",
        "   - Filters out posts with views less than the `min_view_count`.\n",
        "   - Fetches the full content of each post.\n",
        "   - Removes code blocks and calculates the total length of removed code.\n",
        "   - Appends the full content (excluding code blocks) to the post information.\n",
        "5. **Error Handling**:\n",
        "   - Handles HTTP status codes, particularly rate limiting (status code 429).\n",
        "   - Skips over posts with missing elements or if the page fails to load.\n",
        "\n",
        "## Return Value\n",
        "- Returns a list of dictionaries. Each dictionary contains the following keys: 'link', 'upvotes', 'answers', 'views', 'content', and 'code_length'.\n",
        "\n",
        "## Usage Example\n",
        "```python\n",
        "base_url = 'https://stackoverflow.com/questions/tagged/python'\n",
        "filters = ['RecentActivity', 'MostVotes', 'MostFrequent']\n",
        "posts_data = scrape(base_url, filters, total_pages=5, min_view_count=100)\n",
        "print(len(posts_data), \"posts collected.\")\n",
        "```\n",
        "\n",
        "## Notes\n",
        "- The function includes print statements for debugging and progress tracking.\n",
        "- Due to its web scraping nature, the function is dependent on the structure of the Stack Overflow website. Changes in the website's layout or class names may require updates to the selectors used in the function.\n",
        "- The function includes sleep calls to respect the server's load and to comply with web scraping best practices."
      ],
      "metadata": {
        "id": "MexhKn19JtTt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `scrape` function is a Python-based web scraper specifically designed to extract information from posts on Stack Overflow. It focuses on collecting data from posts with non-zero upvotes and retrieves the post link, upvotes count, and textual content.\n",
        "\n",
        "#### Parameters\n",
        "\n",
        "- `base_url` (str): The base URL of the Stack Overflow tag page to scrape.\n",
        "- `filter` (str): The tab filter to apply to the page (e.g., 'active', 'newest', 'frequent', etc.).\n",
        "- `start_page` (int): The starting page number for pagination.\n",
        "- `end_page` (int): The ending page number for pagination.\n",
        "\n",
        "#### How It Works\n",
        "\n",
        "1. **Setup and Initialization**:\n",
        "    - Initializes the `User-Agent` header to mimic a browser request.\n",
        "    - Prepares an empty list, `all_posts_info`, to store the scraped data.\n",
        "\n",
        "2. **Page-wise Iteration**:\n",
        "    - Iterates through each page number from `start_page` to `end_page`.\n",
        "    - Constructs the URL for each page using the `base_url`, `filter`, and current page number.\n",
        "\n",
        "3. **Page Request and Validation**:\n",
        "    - Performs an HTTP GET request to the constructed URL.\n",
        "    - Checks if the response status code is 200 (OK). If not, it logs an error message and proceeds to the next page.\n",
        "\n",
        "4. **HTML Parsing**:\n",
        "    - Parses the page content using BeautifulSoup.\n",
        "    - Selects all elements with the class `question-summary` as post summaries.\n",
        "\n",
        "5. **Post Summaries Validation**:\n",
        "    - Checks if there are any post summaries on the page. If none are found, logs an error and continues to the next page.\n",
        "\n",
        "6. **Individual Post Processing**:\n",
        "    - Iterates over each post summary.\n",
        "    - Extracts the title element (link to the post) and the upvote element.\n",
        "    - Skips any posts with 0 upvotes.\n",
        "    - Constructs the full URL of the post.\n",
        "\n",
        "7. **Fetching Individual Post Content**:\n",
        "    - Makes an HTTP GET request to each post's URL.\n",
        "    - If the request fails, logs an error and continues with the next post.\n",
        "    - Parses the post page and extracts the post content.\n",
        "    - If no content is found, logs an error and continues.\n",
        "\n",
        "8. **Data Aggregation**:\n",
        "    - Appends a dictionary with the post's link, upvote count, and content to `all_posts_info`.\n",
        "\n",
        "9. **Progress Logging**:\n",
        "    - After processing each page, logs the number of posts collected so far.\n",
        "\n",
        "#### Output\n",
        "\n",
        "- Returns `all_posts_info`: A list of dictionaries, where each dictionary contains the following keys:\n",
        "  - `link`: The URL of the post.\n",
        "  - `upvotes`: The number of upvotes the post has received.\n",
        "  - `content`: The textual content of the post.\n",
        "\n",
        "#### Final Output\n",
        "\n",
        "The script prints the total number of posts collected with non-zero upvotes and content, whilst returning a list of dictionaries, where dictionaries represent a row.\n"
      ],
      "metadata": {
        "id": "m5BwI8JT8EHA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "FOR MS JANE TO MODIFY"
      ],
      "metadata": {
        "id": "L91sQcPPSKF3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "############################################\n",
        "# To TEST the program, please SET THE NUMBER_OF_PAGES TO 3.\n",
        "# We need 100 pages to scrape around 5000 rows.\n",
        "NUMBER_OF_PAGES = 2\n",
        "############################################"
      ],
      "metadata": {
        "id": "Dkr07vJ6SOqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "zGammUm2SNAg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "\n",
        "def convert_view_count(view_count_str):\n",
        "    if 'k' in view_count_str:\n",
        "        return int(float(view_count_str.replace('k', '')) * 1000)\n",
        "    elif 'm' in view_count_str:\n",
        "        return int(float(view_count_str.replace('m', '')) * 1000000)\n",
        "    else:\n",
        "        return int(view_count_str)\n",
        "\n",
        "def scrape(base_url, filters, total_pages=3, min_view_count=100):\n",
        "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "    all_posts_info = []\n",
        "\n",
        "    num_filters = len(filters)\n",
        "    pages_scraped = 0\n",
        "    start_time = time.time()\n",
        "\n",
        "    print(f\"Number of filters: {num_filters}\")\n",
        "    print(f\"Total pages requested: {total_pages}\")\n",
        "\n",
        "    # Page distribution logic\n",
        "    if total_pages < num_filters:\n",
        "        pages_to_scrape = [1 if i < total_pages else 0 for i in range(num_filters)]\n",
        "    else:\n",
        "        pages_per_filter = total_pages // num_filters\n",
        "        extra_pages = total_pages % num_filters\n",
        "        pages_to_scrape = [pages_per_filter + (1 if i < extra_pages else 0) for i in range(num_filters)]\n",
        "\n",
        "    print(f\"Pages to scrape per filter: {pages_to_scrape}\")\n",
        "\n",
        "    # Scraping loop\n",
        "    for filter, pages in zip(filters, pages_to_scrape):\n",
        "        print(f\"Scraping filter: {filter}, Pages to scrape: {pages}\")\n",
        "        for page in range(1, pages + 1):\n",
        "            url = f\"{base_url}?sort={filter}&page={page}&pagesize=50\"\n",
        "            print(f\"Scraping URL: {url}\")\n",
        "            response = requests.get(url, headers=headers)\n",
        "            # SLEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEP\n",
        "            # time.sleep()\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                soup = BeautifulSoup(response.text, 'html.parser')\n",
        "                posts = soup.select('.s-post-summary')\n",
        "\n",
        "                for post in posts:\n",
        "                    title_element = post.select_one('.s-post-summary--content-title a')\n",
        "                    upvote_element = post.select_one('.s-post-summary--stats-item-number')\n",
        "\n",
        "                    # Extract answer count\n",
        "                    answer_count_element = post.select_one('div:nth-child(2) > span.s-post-summary--stats-item-number')\n",
        "                    answers = int(answer_count_element.text.strip())\n",
        "\n",
        "                    # Extract view count\n",
        "                    view_count_element = post.select_one('div:nth-child(3) > span.s-post-summary--stats-item-number')\n",
        "                    views = convert_view_count(view_count_element.text.strip())\n",
        "\n",
        "                    if views < min_view_count:\n",
        "                        print(f\"Skipping post, view count less than {min_view_count}: {views}\")\n",
        "                        continue\n",
        "                    title = title_element.text.strip()\n",
        "                    upvotes = int(upvote_element.text.strip())\n",
        "\n",
        "                    link = 'https://stackoverflow.com' + title_element['href']\n",
        "\n",
        "                    # SLEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEP\n",
        "                    # time.sleep(1)\n",
        "                    post_response = requests.get(link, headers=headers)\n",
        "                    if post_response.status_code == 429:\n",
        "                        print(f\"Rate limit hit, saving collected data and exiting...\")\n",
        "                        return all_posts_info\n",
        "\n",
        "                    post_soup = BeautifulSoup(post_response.text, 'html.parser')\n",
        "\n",
        "                     # Select the question container\n",
        "                    question_container = post_soup.select_one('.question.js-question')\n",
        "\n",
        "                    if question_container:\n",
        "                        post_notice = question_container.select_one('.s-notice.s-notice__info.post-notice.js-post-notice.mb16')\n",
        "\n",
        "                        # Remove the post notice if it exists\n",
        "                        if post_notice:\n",
        "                          # print(f\"Skipping post notice, but keeping post content.\")\n",
        "                          post_notice.decompose()\n",
        "\n",
        "                        # Check the length of code blocks\n",
        "                        code_blocks = question_container.select('.js-post-body code')\n",
        "                        # Calculate the total length of code\n",
        "                        total_code_length = sum(len(code_block.get_text(strip=True)) for code_block in code_blocks)\n",
        "\n",
        "                        # Now remove the code blocks to clean up the content\n",
        "                        for code_block in code_blocks:\n",
        "                            code_block.decompose()  # Remove the whole 'pre' element\n",
        "\n",
        "                        post_content_element = question_container.select_one('.js-post-body')\n",
        "\n",
        "                        if not post_content_element:\n",
        "                            print(f\"No content element found for post: {link}. Check the selector.\")\n",
        "                            continue\n",
        "\n",
        "                        post_content = post_content_element.get_text(strip=True)\n",
        "                        full_content = title + \"\\n\" + post_content  # Append title to content\n",
        "\n",
        "                        print(f\"Page {page}: {upvotes} upvotes, {answers} answers, {views} views, {total_code_length} code length,  {len(full_content)} content length.\")\n",
        "\n",
        "                        # Add the post info including code length\n",
        "                        all_posts_info.append({\n",
        "                            'link': link,\n",
        "                            'upvotes': int(upvotes),\n",
        "                            'answers': answers,\n",
        "                            'views': views,\n",
        "                            'content': full_content,\n",
        "                            'code_length': total_code_length\n",
        "                        })\n",
        "\n",
        "                pages_scraped += 1\n",
        "                elapsed_time = time.time() - start_time\n",
        "                avg_time_per_page = elapsed_time / pages_scraped\n",
        "                pages_left = total_pages - pages_scraped\n",
        "                estimated_time_left = avg_time_per_page * pages_left\n",
        "\n",
        "                hours, remainder = divmod(estimated_time_left, 3600)\n",
        "                minutes, seconds = divmod(remainder, 60)\n",
        "\n",
        "                print(f\"\\nPage {page} scraped. {pages_left} pages more to go. Estimated time to completion: {int(hours)}h {int(minutes)}m {int(seconds)}s.\\n\")\n",
        "\n",
        "            elif response.status_code == 429:\n",
        "                print(f\"Rate limit hit, saving collected data and exiting...\")\n",
        "                return all_posts_info\n",
        "            else:\n",
        "                print(f\"Error fetching page {page}, Status Code: {response.status_code}\")\n",
        "                return all_posts_info\n",
        "\n",
        "    return all_posts_info\n",
        "\n",
        "base_url = 'https://stackoverflow.com/questions/tagged/python'\n",
        "filters = ['RecentActivity', 'MostVotes', 'MostFrequent']\n",
        "posts_data = scrape(base_url, filters, total_pages=NUMBER_OF_PAGES, min_view_count=0)\n",
        "print(len(posts_data), \"posts collected.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrTDb9Y0fc10",
        "outputId": "9fae089e-24ec-4428-c0e2-e21dc98f4d76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of filters: 3\n",
            "Total pages requested: 2\n",
            "Pages to scrape per filter: [1, 1, 0]\n",
            "Scraping filter: RecentActivity, Pages to scrape: 1\n",
            "Scraping URL: https://stackoverflow.com/questions/tagged/python?sort=RecentActivity&page=1&pagesize=50\n",
            "Page 1: 0 upvotes, 0 answers, 8 views, 0 code length,  709 content length.\n",
            "Page 1: 0 upvotes, 2 answers, 29 views, 677 code length,  328 content length.\n",
            "Page 1: 0 upvotes, 1 answers, 41 views, 2002 code length,  1223 content length.\n",
            "Page 1: 2 upvotes, 1 answers, 4000 views, 270 code length,  1137 content length.\n",
            "Page 1: 0 upvotes, 0 answers, 9 views, 296 code length,  374 content length.\n",
            "Page 1: 0 upvotes, 1 answers, 21 views, 1222 code length,  216 content length.\n",
            "Page 1: 1 upvotes, 2 answers, 23 views, 451 code length,  452 content length.\n",
            "Page 1: 1 upvotes, 2 answers, 866 views, 765 code length,  361 content length.\n",
            "Page 1: 0 upvotes, 0 answers, 3 views, 3075 code length,  281 content length.\n",
            "Page 1: 0 upvotes, 1 answers, 402 views, 0 code length,  534 content length.\n",
            "Page 1: 0 upvotes, 2 answers, 668 views, 235 code length,  416 content length.\n",
            "Page 1: 0 upvotes, 0 answers, 5 views, 0 code length,  343 content length.\n",
            "Page 1: 0 upvotes, 0 answers, 6 views, 118 code length,  225 content length.\n",
            "Page 1: -1 upvotes, 0 answers, 9 views, 0 code length,  546 content length.\n",
            "Page 1: 4 upvotes, 2 answers, 2000 views, 3087 code length,  517 content length.\n",
            "Page 1: 0 upvotes, 1 answers, 41 views, 719 code length,  286 content length.\n",
            "Page 1: 0 upvotes, 1 answers, 633 views, 0 code length,  481 content length.\n",
            "Page 1: 0 upvotes, 1 answers, 8 views, 0 code length,  604 content length.\n",
            "Page 1: 0 upvotes, 0 answers, 26 views, 289 code length,  1566 content length.\n",
            "Page 1: 2 upvotes, 0 answers, 67 views, 2792 code length,  1015 content length.\n",
            "Page 1: 1 upvotes, 1 answers, 49 views, 476 code length,  380 content length.\n",
            "Page 1: 0 upvotes, 0 answers, 14 views, 3341 code length,  780 content length.\n",
            "Page 1: 0 upvotes, 0 answers, 15 views, 1300 code length,  527 content length.\n",
            "Page 1: 0 upvotes, 1 answers, 16 views, 516 code length,  563 content length.\n",
            "Page 1: 0 upvotes, 0 answers, 21 views, 4412 code length,  581 content length.\n",
            "Page 1: 0 upvotes, 1 answers, 282 views, 1533 code length,  778 content length.\n",
            "Page 1: 29 upvotes, 3 answers, 270000 views, 274 code length,  490 content length.\n",
            "Page 1: -2 upvotes, 3 answers, 411 views, 341 code length,  212 content length.\n",
            "Page 1: 2 upvotes, 2 answers, 121 views, 2640 code length,  619 content length.\n",
            "Page 1: 0 upvotes, 1 answers, 34 views, 974 code length,  1289 content length.\n",
            "Page 1: 0 upvotes, 0 answers, 7 views, 0 code length,  347 content length.\n",
            "Page 1: 2 upvotes, 2 answers, 3000 views, 136 code length,  182 content length.\n",
            "Page 1: 0 upvotes, 0 answers, 12 views, 0 code length,  750 content length.\n",
            "Page 1: 0 upvotes, 0 answers, 11 views, 609 code length,  892 content length.\n",
            "Page 1: 305 upvotes, 33 answers, 836000 views, 246 code length,  499 content length.\n",
            "Page 1: 115 upvotes, 11 answers, 12000 views, 44 code length,  174 content length.\n",
            "Page 1: 0 upvotes, 0 answers, 6 views, 854 code length,  591 content length.\n",
            "Page 1: 0 upvotes, 0 answers, 15 views, 101 code length,  489 content length.\n",
            "Page 1: 0 upvotes, 0 answers, 7 views, 95 code length,  438 content length.\n",
            "Page 1: 0 upvotes, 2 answers, 52 views, 273 code length,  423 content length.\n",
            "Page 1: -1 upvotes, 0 answers, 27 views, 792 code length,  325 content length.\n",
            "Page 1: 0 upvotes, 1 answers, 27 views, 789 code length,  730 content length.\n",
            "Page 1: 1 upvotes, 2 answers, 56 views, 60 code length,  384 content length.\n",
            "Page 1: -1 upvotes, 0 answers, 12 views, 6309 code length,  628 content length.\n",
            "Page 1: 0 upvotes, 0 answers, 9 views, 0 code length,  737 content length.\n",
            "Page 1: 0 upvotes, 1 answers, 28 views, 2801 code length,  543 content length.\n",
            "Page 1: 0 upvotes, 1 answers, 15 views, 647 code length,  409 content length.\n",
            "Page 1: 0 upvotes, 1 answers, 16 views, 0 code length,  680 content length.\n",
            "Page 1: -1 upvotes, 0 answers, 29 views, 278 code length,  336 content length.\n",
            "Page 1: 0 upvotes, 1 answers, 30 views, 1725 code length,  883 content length.\n",
            "\n",
            "Page 1 scraped. 1 pages more to go. Estimated time to completion: 0h 0m 13s.\n",
            "\n",
            "Scraping filter: MostVotes, Pages to scrape: 1\n",
            "Scraping URL: https://stackoverflow.com/questions/tagged/python?sort=MostVotes&page=1&pagesize=50\n",
            "Page 1: 12841 upvotes, 51 answers, 3300000 views, 573 code length,  470 content length.\n",
            "Page 1: 8167 upvotes, 46 answers, 4600000 views, 59 code length,  557 content length.\n",
            "Page 1: 7873 upvotes, 32 answers, 2900000 views, 0 code length,  97 content length.\n",
            "Page 1: 7347 upvotes, 25 answers, 1200000 views, 0 code length,  76 content length.\n",
            "Page 1: 7102 upvotes, 41 answers, 5400000 views, 3 code length,  129 content length.\n",
            "Page 1: 6888 upvotes, 43 answers, 3300000 views, 94 code length,  197 content length.\n",
            "Page 1: 6090 upvotes, 66 answers, 4600000 views, 0 code length,  151 content length.\n",
            "Page 1: 5620 upvotes, 27 answers, 3700000 views, 34 code length,  213 content length.\n",
            "Page 1: 5378 upvotes, 27 answers, 4300000 views, 114 code length,  131 content length.\n",
            "Page 1: 5284 upvotes, 32 answers, 4200000 views, 80 code length,  568 content length.\n",
            "Page 1: 4623 upvotes, 36 answers, 1100000 views, 25 code length,  148 content length.\n",
            "Page 1: 4567 upvotes, 38 answers, 3000000 views, 82 code length,  358 content length.\n",
            "Page 1: 4371 upvotes, 46 answers, 6200000 views, 27 code length,  110 content length.\n",
            "Page 1: 4280 upvotes, 17 answers, 5800000 views, 90 code length,  171 content length.\n",
            "Page 1: 4049 upvotes, 34 answers, 7200000 views, 155 code length,  361 content length.\n",
            "Page 1: 3938 upvotes, 25 answers, 4000000 views, 29 code length,  522 content length.\n",
            "Page 1: 3840 upvotes, 54 answers, 4300000 views, 0 code length,  81 content length.\n",
            "Page 1: 3811 upvotes, 6 answers, 1400000 views, 551 code length,  492 content length.\n",
            "Page 1: 3779 upvotes, 21 answers, 3600000 views, 0 code length,  49 content length.\n",
            "Page 1: 3729 upvotes, 24 answers, 4900000 views, 339 code length,  309 content length.\n",
            "Page 1: 3713 upvotes, 14 answers, 2400000 views, 11 code length,  65 content length.\n",
            "Page 1: 3682 upvotes, 28 answers, 976000 views, 15 code length,  96 content length.\n",
            "Page 1: 3587 upvotes, 10 answers, 6600000 views, 76 code length,  104 content length.\n",
            "Page 1: 3512 upvotes, 21 answers, 5300000 views, 6 code length,  115 content length.\n",
            "Page 1: 3480 upvotes, 17 answers, 6300000 views, 50 code length,  162 content length.\n",
            "Page 1: 3466 upvotes, 21 answers, 8100000 views, 4 code length,  108 content length.\n",
            "Page 1: 3413 upvotes, 34 answers, 5200000 views, 0 code length,  595 content length.\n",
            "Page 1: 3407 upvotes, 34 answers, 264000 views, 274 code length,  1674 content length.\n",
            "Page 1: 3366 upvotes, 28 answers, 1400000 views, 78 code length,  252 content length.\n",
            "Page 1: 3355 upvotes, 17 answers, 3500000 views, 0 code length,  89 content length.\n",
            "Page 1: 3290 upvotes, 41 answers, 2100000 views, 227 code length,  796 content length.\n",
            "Page 1: 3277 upvotes, 24 answers, 2200000 views, 33 code length,  195 content length.\n",
            "Page 1: 3238 upvotes, 31 answers, 4400000 views, 72 code length,  108 content length.\n",
            "Page 1: 3227 upvotes, 27 answers, 4800000 views, 7 code length,  105 content length.\n",
            "Page 1: 3218 upvotes, 16 answers, 3000000 views, 0 code length,  111 content length.\n",
            "Page 1: 3215 upvotes, 11 answers, 3000000 views, 6 code length,  132 content length.\n",
            "Page 1: 3214 upvotes, 7 answers, 2700000 views, 309 code length,  115 content length.\n",
            "Page 1: 3213 upvotes, 13 answers, 3700000 views, 0 code length,  85 content length.\n",
            "Page 1: 3195 upvotes, 15 answers, 6000000 views, 0 code length,  116 content length.\n",
            "Page 1: 3161 upvotes, 65 answers, 2400000 views, 0 code length,  100 content length.\n",
            "Page 1: 3152 upvotes, 22 answers, 654000 views, 78 code length,  147 content length.\n",
            "Page 1: 3111 upvotes, 20 answers, 3300000 views, 16 code length,  122 content length.\n",
            "Page 1: 3103 upvotes, 70 answers, 1600000 views, 0 code length,  216 content length.\n",
            "Page 1: 2994 upvotes, 12 answers, 362000 views, 272 code length,  1375 content length.\n",
            "Page 1: 2982 upvotes, 13 answers, 4700000 views, 0 code length,  201 content length.\n",
            "Page 1: 2951 upvotes, 27 answers, 4500000 views, 52 code length,  140 content length.\n",
            "Page 1: 2944 upvotes, 37 answers, 6300000 views, 55 code length,  95 content length.\n",
            "Page 1: 2871 upvotes, 11 answers, 2700000 views, 49 code length,  392 content length.\n",
            "Page 1: 2768 upvotes, 22 answers, 1300000 views, 122 code length,  178 content length.\n",
            "Page 1: 2751 upvotes, 59 answers, 1800000 views, 3 code length,  182 content length.\n",
            "\n",
            "Page 1 scraped. 0 pages more to go. Estimated time to completion: 0h 0m 0s.\n",
            "\n",
            "Scraping filter: MostFrequent, Pages to scrape: 0\n",
            "100 posts collected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(posts_data)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5zsDPTgOol56",
        "outputId": "d68d83fc-269c-4d5a-c4fa-0d505c243f69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                link  upvotes  answers  views  \\\n",
              "0  https://stackoverflow.com/questions/77918138/h...        0        0      8   \n",
              "1  https://stackoverflow.com/questions/77917814/c...        0        2     29   \n",
              "2  https://stackoverflow.com/questions/77913227/r...        0        1     41   \n",
              "3  https://stackoverflow.com/questions/4897692/fa...        2        1   4000   \n",
              "4  https://stackoverflow.com/questions/77918221/w...        0        0      9   \n",
              "\n",
              "                                             content  code_length  \n",
              "0  how to fix make validate identifier in git?\\nT...            0  \n",
              "1  Character outside of capture group not substit...          677  \n",
              "2  Remove the boxes but keep the labels for a YOL...         2002  \n",
              "3  Fast Bluetooth Name Lookup\\nI'm experiencing p...          270  \n",
              "4  Why wont pydnatic print the id as \"_id\"?\\nHi e...          296  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-75055d9c-1504-4951-89cc-38ec2715e0b6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>link</th>\n",
              "      <th>upvotes</th>\n",
              "      <th>answers</th>\n",
              "      <th>views</th>\n",
              "      <th>content</th>\n",
              "      <th>code_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://stackoverflow.com/questions/77918138/h...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>how to fix make validate identifier in git?\\nT...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://stackoverflow.com/questions/77917814/c...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>29</td>\n",
              "      <td>Character outside of capture group not substit...</td>\n",
              "      <td>677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://stackoverflow.com/questions/77913227/r...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>41</td>\n",
              "      <td>Remove the boxes but keep the labels for a YOL...</td>\n",
              "      <td>2002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://stackoverflow.com/questions/4897692/fa...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4000</td>\n",
              "      <td>Fast Bluetooth Name Lookup\\nI'm experiencing p...</td>\n",
              "      <td>270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://stackoverflow.com/questions/77918221/w...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>Why wont pydnatic print the id as \"_id\"?\\nHi e...</td>\n",
              "      <td>296</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-75055d9c-1504-4951-89cc-38ec2715e0b6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-75055d9c-1504-4951-89cc-38ec2715e0b6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-75055d9c-1504-4951-89cc-38ec2715e0b6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e80284c6-5f83-42fb-921b-513cf946ce91\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e80284c6-5f83-42fb-921b-513cf946ce91')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e80284c6-5f83-42fb-921b-513cf946ce91 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving the function to csv"
      ],
      "metadata": {
        "id": "7TuLZVr8J44l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Export the DataFrame to a CSV file\n",
        "# file_path = \"/content/drive/MyDrive/Y2S2/TSAP/Assignment/\"\n",
        "# df.to_csv(file_path + 'stack_overflow.csv', index=False)\n",
        "\n",
        "# print(\"Data exported to 'stack_overflow.csv'\")"
      ],
      "metadata": {
        "id": "gXCkxCoWlhN8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f051fde5-3469-4359-d31b-984e39588931"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Data exported to 'stack_overflow.csv'\n"
          ]
        }
      ]
    }
  ]
}